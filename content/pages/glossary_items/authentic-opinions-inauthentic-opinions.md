<!DOCTYPE html><html lang="en"><head><title="Authentic Opinions/Inauthentic Opinions"></head>
<body><p><font face="Poppins, Calibri, sans-serif" size="3"><b>Authentic Opinions/<br>Inauthentic Opinions</b></font></p>
<p><font face="Poppins, Calibri, sans-serif" size="2"><b>Asta Zelenkauskaite, </b>, <i>Vilnius Tech, Lithuania &amp; Drexel University, USA</i><br><a href="mailto:az358@drexel.edu" target="blank">az358@drexel.edu</a></font></p>
<p><font face="Poppins, Calibri, sans-serif" size="2"><br><br><br>There are at least two ways to consider authenticity. Authenticity and inauthenticity of opinions first stem from a broad definition of the concept: it can relate to authentic or (in)authentic intentions, sources, or messages, or content in general. With the rise of computational tools that automate dissemination of information online, not all opinions in an online public sphere are produced in an authentic way.  <br><br>Another way of thinking of (in)authenticity by media scholars stems from the perceptual framework, i.e., how we perceive the world through the media. Thus, mediated authenticity suggests that media presents people or things in a specific light, in which they can be perceived as more or less authentic.  <br><br>However, both perspectives entail that authenticity can be constructed and in some cases orchestrated to achieve communicative goals of the message sender.<br><br>Inauthentic public opinions can be written with the help of the automated tools and/or are produced by groups of actors with the underlying agendas, e.g. to influence the discussion. In the scholarship on coordinated inauthentic behaviors, such behaviors can be mediated and amplified by synthetic agents such as online bots and further proliferated by algorithms that typically mediate online spaces.<br><br>Some scholars attribute inauthentic expression of opinions online as astroturfing. While scholars in various fields work on how to detect inauthentic coordinated behaviors, it poses challenges to authentic public opinions.<br><br><br><br></font></p>
<p><font face="Poppins, Calibri, sans-serif" size="2"><b>Keywords</b>: </font></font></span></font><font color="#000000"><span style="text-decoration: none"><font face="calibri, sans-serif"><font size="2" style="font-size: 10pt">a</font></font></span></font><font color="#000000"><span style="text-decoration: none"><font face="calibri, sans-serif"><font size="2" style="font-size: 10pt">uthenticity, inauthentic public sphere, coordinated inauthentic behaviors, astroturfing</font></font></span></font></font></p>
<p><font face="Poppins, Calibri, sans-serif" size="2"><b>Related Entries</b>: <a href="./disinformation.html">Disinformation</a>, <a href="./perspective.html">Perspective</a>, <a href="./sources-of-opinion.html">Sources of Opinion</a></font></p>
<p><font face="Poppins, Calibri, sans-serif" size="2"><b>References</b>:<br>Enli, G. (2015). Mediated authenticity: How the media constructs reality. Peter Lang.<br>Chan, J. (2022). Online astroturfing: A problem beyond disinformation. Philosophy &amp; Social Criticism, 01914537221108467.<br>de-Lima-Santos, M.-F., &amp; Ceron, W. (2024). Coordinated amplification, coordinated inauthentic behaviour, orchestrated campaigns: A systematic literature review of coordinated inauthentic content on online social networks. In T. Erbaysal-Filibeli, &amp; M. Öneren-Özbek (Eds.), Mapping lies in the global media sphere (pp. 165-184). (Routledge Studies in New Media and Cyberculture; Vol. 60). Routledge. <a href="https://doi.org/10.4324/9781003403203-14" target="_blank">https://doi.org/10.4324/9781003403203-14</a><br>Zelenkauskaite, A. (2022). Creating chaos online: Disinformation and subverted post-publics. University of Michigan Press.</font></p>
</body>